{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"execution":{"iopub.execute_input":"2023-03-19T17:51:29.033775Z","iopub.status.busy":"2023-03-19T17:51:29.033143Z","iopub.status.idle":"2023-03-19T17:51:33.524155Z","shell.execute_reply":"2023-03-19T17:51:33.522996Z","shell.execute_reply.started":"2023-03-19T17:51:29.033737Z"},"trusted":true},"outputs":[],"source":["import os\n","import gc\n","import random\n","import multiprocessing\n","import warnings\n","\n","from tqdm.auto import tqdm\n","import numpy as np \n","import pandas as pd\n","from sklearn.model_selection import train_test_split\n","from sklearn.metrics import f1_score\n","\n","import torch\n","import torch.nn as nn\n","from torch.utils.data import DataLoader, Dataset\n","from torch.optim import AdamW\n","from torch.optim.lr_scheduler import ChainedScheduler, LinearLR, ExponentialLR\n","from torch.nn import CrossEntropyLoss\n","\n","from transformers import AutoTokenizer, AutoModel, AutoConfig\n","from transformers import DataCollatorWithPadding\n","\n","from utils import get_title, preprocess_text_field, MeanPooling\n","\n","def seed_everything(seed=42, deterministic=False):\n","    random.seed(seed)\n","    os.environ[\"PYTHONHASHSEED\"] = str(seed)\n","    np.random.seed(seed)\n","    torch.manual_seed(seed)\n","    torch.cuda.manual_seed(seed)\n","    torch.backends.cudnn.deterministic = deterministic\n","    torch.backends.cudnn.benchmark = False"]},{"cell_type":"markdown","metadata":{},"source":["#### Основные настройки: seed, модель, рабочий каталог, warnings."]},{"cell_type":"code","execution_count":2,"metadata":{"execution":{"iopub.execute_input":"2023-03-19T17:51:33.526791Z","iopub.status.busy":"2023-03-19T17:51:33.525967Z","iopub.status.idle":"2023-03-19T17:51:33.916859Z","shell.execute_reply":"2023-03-19T17:51:33.915811Z","shell.execute_reply.started":"2023-03-19T17:51:33.526749Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["env: TOKENIZERS_PARALLELISM=false\n","Device:  cuda\n","CPU cores:  2\n"]}],"source":["SEED = 42\n","WORKDIR = '//kaggle/input/kazan-exress-1/'\n","warnings.filterwarnings(\"ignore\")\n","os.environ['TRANSFORMERS_NO_ADVISORY_WARNINGS'] = 'true'\n","seed_everything(SEED, deterministic=True)\n","\n","%env TOKENIZERS_PARALLELISM=false\n","\n","device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","print(\"Device: \", device)\n","print('CPU cores: ', multiprocessing.cpu_count())\n","\n","# =========================================================================================\n","# Configurations\n","# =========================================================================================\n","class CFG:\n","    num_workers = multiprocessing.cpu_count()\n","    # model = \"sentence-transformers/all-mpnet-base-v2\"\n","    model = 'cointegrated/rubert-tiny2' # os.path.join(WORKDIR, 'LearningEquality/cosineloss_new32')\n","    tokenizer = AutoTokenizer.from_pretrained(model)\n","    state_dict = None\n","    max_length = 256"]},{"cell_type":"markdown","metadata":{},"source":["#### Преобразование входных данных."]},{"cell_type":"code","execution_count":3,"metadata":{"execution":{"iopub.execute_input":"2023-03-19T17:51:33.919575Z","iopub.status.busy":"2023-03-19T17:51:33.918850Z","iopub.status.idle":"2023-03-19T17:51:41.341528Z","shell.execute_reply":"2023-03-19T17:51:41.340495Z","shell.execute_reply.started":"2023-03-19T17:51:33.919534Z"},"trusted":true},"outputs":[],"source":["# Read from parquet\n","data_full = pd.read_parquet(\"/kaggle/input/kazan-exress-1/row_data/train.parquet\")\n","# Drop unnecessary columns\n","data_full.drop(columns=['shop_id', 'rating'], inplace=True)\n","# Convert text fields\n","data_full['title'] = data_full.text_fields.apply(get_title)\n","data_full.text_fields = data_full.text_fields.apply(preprocess_text_field)\n","# Convert \"Sale\"\n","data_full['sale'] = data_full['sale'].apply(lambda x: \"Распродажа!\" if x else \"\")  \n","data_full.fillna(value='', inplace=True)\n","# Concatenate to one string\n","data_full = data_full.assign(Document=[str(y) + ': ' + str(x) + '. ' + str(z) + '. ' + str(s) + '. ' \\\n","                                       for x, y, z, s in zip(data_full['title'], data_full['shop_title'],\n","                                                           data_full['text_fields'], data_full['sale'])])\n","\n","data_full = data_full.drop(columns=['text_fields', 'shop_title', 'sale', 'title']).reset_index(drop=True)\n","# Drop \"product_id\" column - only for train\n","data_full.drop(columns=['product_id'], inplace=True)\n","# Drop too rare values\n","drop_ids = set(data_full.category_id.value_counts()[data_full.category_id.value_counts() < 2].index)\n","data_full = data_full[~data_full['category_id'].isin(drop_ids)]\n","# Trait/test split\n","data, data_valid = train_test_split(data_full, test_size=0.2, random_state=SEED, \n","                                    shuffle=True, stratify=data_full.category_id)\n","data.reset_index(drop=True, inplace=True)\n","data_valid.reset_index(drop=True, inplace=True)\n","# Fix class umbers \n","cls2id = data_full.category_id.unique()\n","id2cls = {k : v for v, k in enumerate(cls2id)}\n","\n","del data_full"]},{"cell_type":"markdown","metadata":{},"source":["#### Классы модели и датасета."]},{"cell_type":"code","execution_count":4,"metadata":{"execution":{"iopub.execute_input":"2023-03-19T17:51:41.345241Z","iopub.status.busy":"2023-03-19T17:51:41.344837Z","iopub.status.idle":"2023-03-19T17:51:41.362394Z","shell.execute_reply":"2023-03-19T17:51:41.361220Z","shell.execute_reply.started":"2023-03-19T17:51:41.345201Z"},"trusted":true},"outputs":[],"source":["# =========================================================================================\n","# Prepare input, tokenize\n","# =========================================================================================\n","def prepare_input(text, cfg):\n","    inputs = cfg.tokenizer(\n","        text, \n","        return_tensors = None, \n","        add_special_tokens = True, \n","        max_length=cfg.max_length,\n","        truncation=True\n","    )\n","    return inputs\n","\n","# =========================================================================================\n","# Dataset\n","# =========================================================================================\n","class doc_dataset(Dataset):\n","    def __init__(self, documents:list, targets: list, id2cls: dict, cfg):\n","        self.cfg = cfg\n","        self.data = documents\n","        self.targets = targets\n","        self.id2cls = id2cls\n","    def __len__(self):\n","        return len(self.data)\n","    def __getitem__(self, item):\n","        return prepare_input(self.data[item], self.cfg), self.id2cls[self.targets[item]]\n","\n","# =========================================================================================\n","# Unsupervised model\n","# =========================================================================================\n","class BERT_CLF(nn.Module):\n","    def __init__(self, cfg, n_classes, cut_emb=None, emb_act=None, bottleneck_size=None, bottleneck_act=None):\n","        super().__init__()\n","        self.cfg = cfg\n","        self.config = AutoConfig.from_pretrained(cfg.model)\n","        self.model = AutoModel.from_pretrained(cfg.model, config = self.config)\n","        self.pool = MeanPooling()\n","        # Cutting of BERT embeddings\n","        if cut_emb is not None:\n","            self.in_size = cut_emb\n","            self.cut_emb = True\n","        else:\n","            self.in_size = self.model.config.hidden_size\n","            self.cut_emb = False\n","        # Activation for BERT embeddings\n","        if emb_act is None:\n","            self.emb_bn = nn.Identity()\n","            self.emb_act = nn.Identity()\n","        else:\n","            self.emb_bn = nn.BatchNorm1d(self.in_size)\n","            self.emb_act = emb_act\n","        # Additional bottleneck layer\n","        if bottleneck_size is None:\n","            bott_out_size = self.in_size\n","            self.bott_act = nn.Identity()\n","            self.bott_fc = nn.Identity()\n","        else:\n","            bott_out_size = bottleneck_size\n","            self.bott_act = bottleneck_act\n","            self.bott_fc = nn.Linear(self.in_size, bott_out_size)\n","        \n","        # Classifier\n","        self.clf = nn.Linear(bott_out_size, n_classes)\n","\n","    def forward(self, inputs):\n","        emb = self.pool(self.model(**inputs).last_hidden_state, inputs['attention_mask'])\n","        \n","        if self.cut_emb:\n","            emb = emb[:, :self.in_size]\n","        \n","        x = self.emb_act(self.emb_bn(emb))\n","        x = self.bott_act(self.bott_fc(x))\n","        \n","        cls  = self.clf(x)\n","        return cls"]},{"cell_type":"markdown","metadata":{},"source":["#### Даталоадер и функция collate_fn"]},{"cell_type":"code","execution_count":5,"metadata":{"execution":{"iopub.execute_input":"2023-03-19T17:51:41.364601Z","iopub.status.busy":"2023-03-19T17:51:41.364165Z","iopub.status.idle":"2023-03-19T17:51:41.386021Z","shell.execute_reply":"2023-03-19T17:51:41.384848Z","shell.execute_reply.started":"2023-03-19T17:51:41.364563Z"},"trusted":true},"outputs":[],"source":["transformers_collator = DataCollatorWithPadding(tokenizer = CFG.tokenizer, padding = 'longest')\n","\n","def custom_collate(batch):\n","    doc_batch = []\n","    targets_batch = []\n","    for pair in batch:\n","        doc_batch.append(pair[0])\n","        targets_batch.append(pair[1])\n","    return transformers_collator(doc_batch), torch.tensor(targets_batch)\n","\n","train_loader = DataLoader(\n","    doc_dataset(data.Document.tolist(), data.category_id.tolist(), id2cls, CFG), \n","    batch_size = 384, \n","    shuffle = True, \n","    collate_fn = custom_collate,\n","    num_workers = CFG.num_workers, \n","    pin_memory = True, \n","    drop_last = False\n",")\n","\n","valid_loader = DataLoader(\n","    doc_dataset(data_valid.Document.tolist(), data_valid.category_id.tolist(), id2cls, CFG), \n","    batch_size = 384, \n","    shuffle = False, \n","    collate_fn = custom_collate,\n","    num_workers = CFG.num_workers, \n","    pin_memory = True, \n","    drop_last = False\n",")"]},{"cell_type":"markdown","metadata":{},"source":["#### Train loop."]},{"cell_type":"code","execution_count":6,"metadata":{"execution":{"iopub.execute_input":"2023-03-19T17:51:41.388507Z","iopub.status.busy":"2023-03-19T17:51:41.388065Z","iopub.status.idle":"2023-03-19T17:51:41.415832Z","shell.execute_reply":"2023-03-19T17:51:41.414695Z","shell.execute_reply.started":"2023-03-19T17:51:41.388468Z"},"trusted":true},"outputs":[],"source":["def train(model, train_loader, test_loader, weight_decay=1e-6,\n","          epochs=2, lr=0.0001, checkpoint_period=None, \n","          warmup_epochs=3, gamma=0.925, verbose=True):\n","    \n","    opt = AdamW(model.parameters(), lr=lr * gamma ** -warmup_epochs, weight_decay=weight_decay)\n","    \n","    model.to(device)\n","    loss_fn = torch.nn.CrossEntropyLoss(label_smoothing=0.02)   \n","    opt.zero_grad() \n","    torch.cuda.empty_cache()\n","    gc.collect()\n","    scheduler = ChainedScheduler([LinearLR(opt, start_factor=0.01, total_iters=warmup_epochs),\n","                                  ExponentialLR(opt, gamma=gamma)])\n","    if checkpoint_period is None:\n","        checkpoint_period = len(train_loader)\n","    \n","    max_f1 = 0.\n","    best_epoch = 0\n","    \n","    for epoch in tqdm(range(1, epochs+1, 1)):\n","        # TRAIN\n","        model.train()\n","        loss_avg = 0.\n","        if verbose:\n","            print(f'Epoch={epoch}')\n","            print(f'Lr: {scheduler.get_last_lr()[0]:.9f}')\n","        for step, batch in tqdm(enumerate(train_loader), total=len(train_loader), disable = not verbose):\n","            input = batch[0].to(device)\n","            target = batch[1].to(device)\n","            output = model(input)\n","            loss = loss_fn(output, target)\n","            loss.backward()\n","            opt.step()\n","            opt.zero_grad()\n","            loss_avg += loss.item() / checkpoint_period\n","            if step % checkpoint_period == checkpoint_period - 1:\n","                if verbose:\n","                    print(f'Step={step+1}, Train loss={loss_avg:.6f}')\n","                loss_avg = 0.\n","                torch.save(model.state_dict(), '/kaggle/working/checkpoint.pt')\n","                model.eval()\n","                grun_truth = []\n","                predicted = []                \n","                with torch.no_grad():\n","                    precision = 0.\n","                    recall = 0.\n","                    total = min(len(test_loader), (checkpoint_period // 2))\n","                    for step, batch in enumerate(test_loader):\n","                        input = batch[0].to(device)\n","                        target = batch[1].to(device)\n","                        output = model(input)\n","                        loss = loss_fn(output, target)\n","                        loss_avg += loss.item() / total\n","                        grun_truth.append(target.cpu())\n","                        predicted.append(output.argmax(dim=1).cpu())\n","                        if step >= checkpoint_period // 2 - 1:\n","                            break\n","                weighted_f1 = f1_score(np.concatenate(grun_truth), np.concatenate(predicted), average='weighted')\n","                if weighted_f1 > max_f1:\n","                    max_f1 = weighted_f1\n","                    best_epoch = epoch\n","                    torch.save(model.state_dict(), os.path.join(WORKDIR, 'best.pt'))\n","                if verbose:\n","                    print(f\"F1={weighted_f1:.5f}\")\n","                    print(f'Eval loss={loss_avg:.5f}\\n')\n","                loss_avg = 0.\n","                model.train()\n","                scheduler.step()\n","                print(f'Lr: {scheduler.get_last_lr()[0]:.9f}')\n","    return max_f1, best_epoch"]},{"cell_type":"code","execution_count":7,"metadata":{"execution":{"iopub.execute_input":"2023-03-19T17:51:41.417835Z","iopub.status.busy":"2023-03-19T17:51:41.417341Z","iopub.status.idle":"2023-03-19T17:51:44.872686Z","shell.execute_reply":"2023-03-19T17:51:44.871552Z","shell.execute_reply.started":"2023-03-19T17:51:41.417789Z"},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["Some weights of the model checkpoint at cointegrated/rubert-tiny2 were not used when initializing BertModel: ['cls.predictions.decoder.weight', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight', 'cls.predictions.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.decoder.bias']\n","- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"]},{"data":{"text/plain":["148"]},"execution_count":7,"metadata":{},"output_type":"execute_result"}],"source":["model = BERT_CLF(CFG, len(cls2id)).to(device)\n","if CFG.state_dict is not None:\n","    model.load_state_dict(CFG.state_dict)\n","torch.cuda.empty_cache()\n","gc.collect()"]},{"cell_type":"markdown","metadata":{},"source":["#### Обучение модели."]},{"cell_type":"code","execution_count":8,"metadata":{"execution":{"iopub.execute_input":"2023-03-19T17:51:44.875901Z","iopub.status.busy":"2023-03-19T17:51:44.874141Z","iopub.status.idle":"2023-03-19T18:20:43.443855Z","shell.execute_reply":"2023-03-19T18:20:43.442579Z","shell.execute_reply.started":"2023-03-19T17:51:44.875859Z"},"trusted":true},"outputs":[{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"78d0e1728b154f7ca830b398bafc7570","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/14 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["Epoch=1\n","Lr: 0.000009350\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"b0773c6125ab40da951f2473c81e4070","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/190 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["Step=190, Train loss=6.317847\n","F1=0.03371\n","Eval loss=5.91598\n","\n","Lr: 0.000436757\n","Epoch=2\n","Lr: 0.000436757\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"5bb84ef5f05d4a77a7e9eba1879977a7","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/190 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["Step=190, Train loss=2.062790\n","F1=0.81480\n","Eval loss=0.93279\n","\n","Lr: 0.000800000\n","Epoch=3\n","Lr: 0.000800000\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"7a12d68949024b64b2f1dcc1fc469142","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/190 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["Step=190, Train loss=0.780800\n","F1=0.85778\n","Eval loss=0.76492\n","\n","Lr: 0.000740000\n","Epoch=4\n","Lr: 0.000740000\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"305e7c1102b848038353f190c465726d","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/190 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["Step=190, Train loss=0.500762\n","F1=0.86809\n","Eval loss=0.75219\n","\n","Lr: 0.000684500\n","Epoch=5\n","Lr: 0.000684500\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"9e41b2b0c99042b2b31beb478c5d2e7c","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/190 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["Step=190, Train loss=0.367809\n","F1=0.87432\n","Eval loss=0.76172\n","\n","Lr: 0.000633163\n","Epoch=6\n","Lr: 0.000633163\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"8f771d5770ad4f2db87b6e72e3fc2dc2","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/190 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["Step=190, Train loss=0.309968\n","F1=0.87982\n","Eval loss=0.77572\n","\n","Lr: 0.000585675\n","Epoch=7\n","Lr: 0.000585675\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"c84b47c7e9704357a82152e429d6cb9f","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/190 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["Step=190, Train loss=0.282066\n","F1=0.87982\n","Eval loss=0.79210\n","\n","Lr: 0.000541750\n","Epoch=8\n","Lr: 0.000541750\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"bbd5620349724c4d9847a17f73ed8c4a","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/190 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["Step=190, Train loss=0.270308\n","F1=0.88205\n","Eval loss=0.78881\n","\n","Lr: 0.000501118\n","Epoch=9\n","Lr: 0.000501118\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"f6f127dc782b426b8e478cf8ab6eafa4","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/190 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["Step=190, Train loss=0.263380\n","F1=0.88186\n","Eval loss=0.80188\n","\n","Lr: 0.000463535\n","Epoch=10\n","Lr: 0.000463535\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"e1689759905d4a1c820d4827c2186579","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/190 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["Step=190, Train loss=0.259345\n","F1=0.88305\n","Eval loss=0.80466\n","\n","Lr: 0.000428769\n","Epoch=11\n","Lr: 0.000428769\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"acff67eb4e5643b880d6b979b6253ec5","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/190 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["Step=190, Train loss=0.256448\n","F1=0.88479\n","Eval loss=0.80578\n","\n","Lr: 0.000396612\n","Epoch=12\n","Lr: 0.000396612\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"9051cce206984a8cb19067d0cb168648","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/190 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["Step=190, Train loss=0.253435\n","F1=0.88260\n","Eval loss=0.81456\n","\n","Lr: 0.000366866\n","Epoch=13\n","Lr: 0.000366866\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"8911d9469c6e44bf80ed211b8f9dd09f","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/190 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["Step=190, Train loss=0.251561\n","F1=0.88406\n","Eval loss=0.81530\n","\n","Lr: 0.000339351\n","Epoch=14\n","Lr: 0.000339351\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"9f4a0714e201419aa0e265eb003ab31e","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/190 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["Step=190, Train loss=0.249865\n","F1=0.88487\n","Eval loss=0.81790\n","\n","Lr: 0.000313900\n"]},{"data":{"text/plain":["(0.8848723999530534, 14)"]},"execution_count":8,"metadata":{},"output_type":"execute_result"}],"source":["train(model, train_loader, valid_loader, warmup_epochs=2, epochs=14, lr=0.0008)"]},{"cell_type":"code","execution_count":9,"metadata":{"execution":{"iopub.execute_input":"2023-03-19T18:20:43.446872Z","iopub.status.busy":"2023-03-19T18:20:43.446108Z","iopub.status.idle":"2023-03-19T18:20:43.979607Z","shell.execute_reply":"2023-03-19T18:20:43.978668Z","shell.execute_reply.started":"2023-03-19T18:20:43.446825Z"},"trusted":true},"outputs":[{"data":{"text/plain":["1000"]},"execution_count":9,"metadata":{},"output_type":"execute_result"}],"source":["del model\n","torch.cuda.empty_cache()\n","gc.collect()"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["model.model.save_pretrained(os.path.join(WORKDIR, 'ruberttiny2_pretrained_08data'))\n","CFG.tokenizer.save_pretrained(os.path.join(WORKDIR, \"ruberttiny2_pretrained_08data/tokenizer/\"))"]},{"cell_type":"markdown","metadata":{},"source":["### Подбор гиперпараметров."]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["def try_parameters(lr=0.0008, epochs=20, warmup_epochs=2, cut_emb=None, weight_decay=1e-6,\n","                   emb_act=None, bottleneck_size=None, bottleneck_act=None,\n","                   verbose=False):\n","    \n","    model = BERT_CLF(CFG, len(cls2id), cut_emb=cut_emb, \n","                     emb_act=emb_act, bottleneck_size=bottleneck_size, bottleneck_act=bottleneck_act\n","                     ).to(device)\n","    \n","    torch.cuda.empty_cache()\n","    gc.collect()\n","    \n","    f1, epoch = train(model, train_loader, valid_loader, weight_decay=weight_decay,\n","               warmup_epochs=warmup_epochs, epochs=epochs, lr=lr,\n","               verbose=verbose)\n","    print(f\"lr={lr}, epochs={epochs}, warmup_epochs={warmup_epochs}, emb_act={emb_act}, \" \n","          f\"bottleneck_size={bottleneck_size}, bottleneck_act={bottleneck_act}, weight_decay={weight_decay}\")\n","    print(f\"Best F1={f1:.5f}, Best epoch={epoch}\\n\")"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["for weight_decay in tqdm([0.1, 0.001, 1e-3, 1e-4, 1e-5, 1e-6, 1e-7]):\n","    for lr in [0.0008, 0.0015, 0.0004]:\n","        try_parameters(lr=lr, epochs=20, warmup_epochs=2, weight_decay=weight_decay, verbose=False)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.12"},"vscode":{"interpreter":{"hash":"73baa7047eb6901c2be83950c21fe663ea57cccf327cab8d2ef6784beacf294e"}}},"nbformat":4,"nbformat_minor":4}
