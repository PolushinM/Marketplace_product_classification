{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-20T20:08:10.550660Z",
     "iopub.status.busy": "2023-03-20T20:08:10.550267Z",
     "iopub.status.idle": "2023-03-20T20:08:15.657358Z",
     "shell.execute_reply": "2023-03-20T20:08:15.656165Z",
     "shell.execute_reply.started": "2023-03-20T20:08:10.550624Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import gc\n",
    "import random\n",
    "import multiprocessing\n",
    "import warnings\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "from PIL import Image\n",
    "import numpy as np \n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torch.optim import AdamW\n",
    "from torch.optim.lr_scheduler import ChainedScheduler, LinearLR, ExponentialLR\n",
    "from torch.nn import CrossEntropyLoss\n",
    "from torch.utils.data import default_collate\n",
    "\n",
    "from transformers import AutoTokenizer, AutoModel, AutoConfig\n",
    "from transformers import DataCollatorWithPadding\n",
    "from transformers import CLIPProcessor, CLIPModel, CLIPTokenizerFast\n",
    "\n",
    "from utils import get_title, preprocess_text_field, MeanPooling, Attention\n",
    "\n",
    "def seed_everything(seed=42, deterministic=False):\n",
    "    random.seed(seed)\n",
    "    os.environ[\"PYTHONHASHSEED\"] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = deterministic\n",
    "    torch.backends.cudnn.benchmark = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Основные настройки: seed, модель, рабочий каталог, warnings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-20T20:53:20.057369Z",
     "iopub.status.busy": "2023-03-20T20:53:20.056655Z",
     "iopub.status.idle": "2023-03-20T20:53:21.378214Z",
     "shell.execute_reply": "2023-03-20T20:53:21.377164Z",
     "shell.execute_reply.started": "2023-03-20T20:53:20.057332Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: TOKENIZERS_PARALLELISM=false\n",
      "Device:  cuda\n",
      "CPU cores:  8\n"
     ]
    }
   ],
   "source": [
    "SEED = 42\n",
    "WORKDIR = '//home/ubuntu/gitrepo/KazanExpress/2/'\n",
    "IMAGES_FOLDER = os.path.join(WORKDIR, 'row_data/images/train/')\n",
    "IMAGES_FOLDER_TEST = os.path.join(WORKDIR, 'row_data/images/test/')\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "os.environ['TRANSFORMERS_NO_ADVISORY_WARNINGS'] = 'true'\n",
    "seed_everything(seed=42, deterministic=True)\n",
    "\n",
    "%env TOKENIZERS_PARALLELISM=false\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(\"Device: \", device)\n",
    "print('CPU cores: ', multiprocessing.cpu_count())\n",
    "\n",
    "# =========================================================================================\n",
    "# Configurations\n",
    "# =========================================================================================\n",
    "class CFG:\n",
    "    num_workers = multiprocessing.cpu_count()\n",
    "    clip_model = \"openai/clip-vit-large-patch14\"\n",
    "    clip_tokenizer = CLIPTokenizerFast.from_pretrained(clip_model)\n",
    "    clip_processor = CLIPProcessor.from_pretrained(clip_model)\n",
    "    clip_embeddings = np.load('embeddings_clip.np.npy')\n",
    "    clip_embeddings_test = np.load('embeddings_clip_test.np.npy')\n",
    "    clip_cut_emb = 40\n",
    "    bert_model = 'cointegrated/rubert-tiny2' \n",
    "    bert_tokenizer = AutoTokenizer.from_pretrained('cointegrated/rubert-tiny2')\n",
    "    bert_cut_emb = None\n",
    "    state_dict = None\n",
    "    max_length = 256\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Преобразование входных данных."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-20T20:08:16.978532Z",
     "iopub.status.busy": "2023-03-20T20:08:16.977794Z",
     "iopub.status.idle": "2023-03-20T20:08:23.555230Z",
     "shell.execute_reply": "2023-03-20T20:08:23.554134Z",
     "shell.execute_reply.started": "2023-03-20T20:08:16.978491Z"
    }
   },
   "outputs": [],
   "source": [
    "# Read from parquet\n",
    "data_full = pd.read_parquet(os.path.join(WORKDIR, 'row_data/new/train.parquet'))\n",
    "# Drop unnecessary columns\n",
    "data_full.drop(columns=['shop_id', 'rating'], inplace=True)\n",
    "# Convert text fields\n",
    "data_full['title'] = data_full.text_fields.apply(get_title)\n",
    "data_full.text_fields = data_full.text_fields.apply(preprocess_text_field)\n",
    "# Convert \"Sale\"\n",
    "data_full['sale'] = data_full['sale'].apply(lambda x: \"Распродажа!\" if x else \"\")  \n",
    "data_full.fillna(value='', inplace=True)\n",
    "# Concatenate to one string\n",
    "data_full = data_full.assign(Document=[str(y) + ': ' + str(x) + '. ' + str(z) + '. ' + str(s) + '. ' \\\n",
    "                                       for x, y, z, s in zip(data_full['title'], data_full['shop_title'],\n",
    "                                                           data_full['text_fields'], data_full['sale'])])\n",
    "\n",
    "data_full = data_full.drop(columns=['text_fields', 'shop_title', 'sale', 'title']).reset_index(drop=True)\n",
    "# Duplicate too rare values\n",
    "dup_ids = set(data_full.category_id.value_counts()[data_full.category_id.value_counts() < 2].index)\n",
    "data_full = data_full.append(data_full[data_full['category_id'].isin(dup_ids)])\n",
    "# Trait/test split\n",
    "if CFG.clip_embeddings is not None:\n",
    "    data, data_valid, clip_embeddings, clip_embeddings_valid = train_test_split(data_full, CFG.clip_embeddings, \n",
    "                                                                    test_size=0.025, random_state=SEED, \n",
    "                                                                    shuffle=True, stratify=data_full.category_id)\n",
    "else:\n",
    "    data, data_valid_stack = train_test_split(data_full, test_size=0.025, random_state=SEED, \n",
    "                                        shuffle=True, stratify=data_full.category_id)\n",
    "    \n",
    "data.reset_index(drop=True, inplace=True)\n",
    "data_valid.reset_index(drop=True, inplace=True)\n",
    "# Fix class umbers \n",
    "cls2id = data_full.category_id.unique()\n",
    "id2cls = {k : v for v, k in enumerate(cls2id)}\n",
    "\n",
    "# del data_full\n",
    "id2category = {k:v[15:] for k, v in zip(data_full.category_id.tolist(), data_full.category_name.tolist())}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Преобразование входных данных из файла \"test\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read from parquet\n",
    "data_test = pd.read_parquet(os.path.join(WORKDIR, 'row_data/new/test.parquet'))\n",
    "# Drop unnecessary columns\n",
    "data_test.drop(columns=['shop_id', 'rating'], inplace=True)\n",
    "# Convert text fields\n",
    "data_test['title'] = data_test.text_fields.apply(get_title)\n",
    "data_test.text_fields = data_test.text_fields.apply(preprocess_text_field)\n",
    "# Convert \"Sale\"\n",
    "data_test['sale'] = data_test['sale'].apply(lambda x: \"Распродажа!\" if x else \"\")  \n",
    "data_test.fillna(value='', inplace=True)\n",
    "# Concatenate to one string\n",
    "data_test = data_test.assign(Document=[str(y) + ': ' + str(x) + '. ' + str(z) + '. ' + str(s) + '. ' \\\n",
    "                                       for x, y, z, s in zip(data_test['title'], data_test['shop_title'],\n",
    "                                                           data_test['text_fields'], data_test['sale'])])\n",
    "\n",
    "data_test = data_test.drop(columns=['text_fields', 'shop_title', 'sale', 'title']).reset_index(drop=True)\n",
    "data_test.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-19T13:32:39.393451Z",
     "iopub.status.busy": "2023-03-19T13:32:39.392979Z",
     "iopub.status.idle": "2023-03-19T13:32:40.435364Z",
     "shell.execute_reply": "2023-03-19T13:32:40.434319Z",
     "shell.execute_reply.started": "2023-03-19T13:32:39.393403Z"
    }
   },
   "source": [
    "#### Классы датасета и модели. \n",
    "Модель и датасет позволяют загружать как модель CLIP (собственную или с huggingface), так и готовые (ранее сгенерированные и сохранунные в numpy array) эмбеддинги CLIP."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-20T20:08:23.557677Z",
     "iopub.status.busy": "2023-03-20T20:08:23.556761Z",
     "iopub.status.idle": "2023-03-20T20:08:23.578410Z",
     "shell.execute_reply": "2023-03-20T20:08:23.577266Z",
     "shell.execute_reply.started": "2023-03-20T20:08:23.557635Z"
    }
   },
   "outputs": [],
   "source": [
    "# =========================================================================================\n",
    "# Dataset\n",
    "# =========================================================================================\n",
    "class stacked_dataset(Dataset):\n",
    "    def __init__(self, cfg, documents:list, targets: list, \n",
    "                 id2cls: dict, images_folder: str, \n",
    "                 product_ids:list, clip_embeddings=None):\n",
    "        # Use precalculated embeddings or preprocess images\n",
    "        if clip_embeddings is not None:\n",
    "            self.use_precalculated_clip_embs = True\n",
    "            self.clip_embeddings = clip_embeddings\n",
    "        else:\n",
    "            self.use_precalculated_clip_embs = False\n",
    "        \n",
    "        self.cfg = cfg\n",
    "        self.data = documents\n",
    "        self.targets = targets\n",
    "        self.id2cls = id2cls\n",
    "        self.images_folder = images_folder\n",
    "        self.product_ids = product_ids\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "    \n",
    "    def __getitem__(self, item):\n",
    "        # Use precalculated embeddings or preprocess images\n",
    "        if self.use_precalculated_clip_embs:\n",
    "            image_inputs = self.clip_embeddings[item][None, :]\n",
    "        else:\n",
    "            image = Image.open(os.path.join(self.images_folder, str(self.product_ids[item]) + '.jpg'))\n",
    "            image_inputs = self.cfg.clip_processor(\n",
    "                    text=None,\n",
    "                    images=image,\n",
    "                    return_tensors='pt'\n",
    "                )['pixel_values']\n",
    "        # Preprocess text for BERT\n",
    "        text_inputs=self.cfg.bert_tokenizer(\n",
    "                self.data[item], \n",
    "                return_tensors=None, \n",
    "                add_special_tokens=True, \n",
    "                max_length=self.cfg.max_length,\n",
    "                truncation=True\n",
    "            )\n",
    "                \n",
    "        return text_inputs, image_inputs, self.id2cls[self.targets[item]]\n",
    "\n",
    "# =========================================================================================\n",
    "# Classifier model\n",
    "# =========================================================================================\n",
    "class STACKED_CLF(nn.Module):\n",
    "    def __init__(self, cfg, n_classes, img_emb_mult=0.001):\n",
    "        super().__init__()\n",
    "        # Configurations, CLIP and BERT models loading\n",
    "        self.cfg = cfg\n",
    "        self.img_emb_mult = img_emb_mult\n",
    "        if cfg.clip_embeddings is None:\n",
    "            self.clip_config = AutoConfig.from_pretrained(cfg.model)\n",
    "            self.clip_model = CLIPModel.from_pretrained(cfg.model)\n",
    "        else: \n",
    "            self.use_precalculated_clip_embs = True\n",
    "        self.bert_config = AutoConfig.from_pretrained(cfg.bert_model)\n",
    "        self.bert_model = AutoModel.from_pretrained(cfg.bert_model, config = self.bert_config)\n",
    "        self.bert_pool = MeanPooling()\n",
    "        # CLIP embeddings from model or precalculated\n",
    "        if cfg.bert_cut_emb is None:\n",
    "            self.hidden_dim = self.bert_model.config.hidden_size + cfg.clip_cut_emb\n",
    "        else:\n",
    "            self.hidden_dim = cfg.bert_cut_emb + cfg.clip_cut_emb\n",
    "        # Attentions\n",
    "        self.attention_clip = Attention(self.hidden_dim-cfg.clip_cut_emb, cfg.clip_cut_emb)\n",
    "        self.attention_bert = Attention(cfg.clip_cut_emb, self.hidden_dim-cfg.clip_cut_emb)\n",
    "        # Classifier\n",
    "        self.bn = nn.BatchNorm1d(self.hidden_dim)\n",
    "        self.clf = nn.Linear(self.hidden_dim, n_classes)\n",
    "\n",
    "    def forward(self, text_inputs, image_inputs):\n",
    "        # Get BERT embeddings from text\n",
    "        text_emb = self.bert_model(**text_inputs)\n",
    "        text_emb = self.bert_pool(text_emb.last_hidden_state, text_inputs['attention_mask']) \n",
    "        # Get CLIP embeddings from pictures\n",
    "        if self.use_precalculated_clip_embs:\n",
    "            img_emb = image_inputs \n",
    "        else:\n",
    "            img_emb = self.clip_model.get_image_features(image_inputs)\n",
    "        # Cut embeddings\n",
    "        text_emb = text_emb[:, :self.cfg.bert_cut_emb]\n",
    "        img_emb = img_emb[:, :self.cfg.clip_cut_emb]\n",
    "        # Apply attentions\n",
    "        img_emb = self.attention_clip(text_emb, img_emb) * self.img_emb_mult # Regularisation\n",
    "        text_emb = self.attention_bert(img_emb, text_emb)\n",
    "        # Concatenate BERT and CLIP embeddings\n",
    "        emb  = torch.cat([text_emb, img_emb], dim=1).float()\n",
    "        # Classifier\n",
    "        cls = self.clf(self.bn(emb))\n",
    "        return cls"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Функция collate_fn и даталоадер:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-20T20:08:23.581517Z",
     "iopub.status.busy": "2023-03-20T20:08:23.580624Z",
     "iopub.status.idle": "2023-03-20T20:08:23.603541Z",
     "shell.execute_reply": "2023-03-20T20:08:23.602477Z",
     "shell.execute_reply.started": "2023-03-20T20:08:23.581479Z"
    }
   },
   "outputs": [],
   "source": [
    "transformers_collator = DataCollatorWithPadding(tokenizer = CFG.bert_tokenizer, padding = 'longest')\n",
    "\n",
    "def custom_collate(batch):\n",
    "    texts_batch = []\n",
    "    images_batch = []\n",
    "    targets_batch = []\n",
    "    for item in batch:\n",
    "        texts_batch.append(item[0])\n",
    "        images_batch.append(item[1][0])\n",
    "        targets_batch.append(item[2])\n",
    "    text_inputs = transformers_collator(texts_batch)\n",
    "    return text_inputs, default_collate(images_batch), default_collate(targets_batch)\n",
    "\n",
    "\n",
    "train_loader = DataLoader(\n",
    "    stacked_dataset(CFG, documents=data.Document.tolist(), targets=data.category_id.tolist(), \n",
    "                  id2cls=id2cls, images_folder=IMAGES_FOLDER, \n",
    "                  product_ids=data.product_id.tolist(), clip_embeddings=clip_embeddings), \n",
    "    batch_size = 256, \n",
    "    shuffle = True, \n",
    "    collate_fn = custom_collate,\n",
    "    num_workers = CFG.num_workers, \n",
    "    pin_memory = True, \n",
    "    drop_last = False\n",
    ")\n",
    "\n",
    "valid_loader = DataLoader(\n",
    "    stacked_dataset(CFG, documents=data_valid.Document.tolist(), targets=data_valid.category_id.tolist(), \n",
    "                  id2cls=id2cls, images_folder=IMAGES_FOLDER, \n",
    "                  product_ids=data_valid.product_id.tolist(), clip_embeddings=clip_embeddings_valid), \n",
    "    batch_size = 512, \n",
    "    shuffle = False, \n",
    "    collate_fn = custom_collate,\n",
    "    num_workers = CFG.num_workers, \n",
    "    pin_memory = True, \n",
    "    drop_last = False\n",
    ")\n",
    "\n",
    "full_loader = DataLoader(\n",
    "    stacked_dataset(CFG, documents=data_full.Document.tolist(), targets=data_full.category_id.tolist(), \n",
    "                  id2cls=id2cls, images_folder=IMAGES_FOLDER, \n",
    "                  product_ids=data_full.product_id.tolist(), clip_embeddings=CFG.clip_embeddings), \n",
    "    batch_size = 512, \n",
    "    shuffle = False, \n",
    "    collate_fn = custom_collate,\n",
    "    num_workers = CFG.num_workers, \n",
    "    pin_memory = True, \n",
    "    drop_last = False\n",
    ")\n",
    "\n",
    "test_loader = DataLoader(\n",
    "    stacked_dataset(CFG, documents=data_test.Document.tolist(), targets=[2789] * len(data_test.product_id.tolist()), \n",
    "                  id2cls=id2cls, images_folder=IMAGES_FOLDER_TEST, \n",
    "                  product_ids=data_test.product_id.tolist(), clip_embeddings=CFG.clip_embeddings_test), \n",
    "    batch_size = 256, \n",
    "    shuffle = False, \n",
    "    collate_fn = custom_collate,\n",
    "    num_workers = CFG.num_workers, \n",
    "    pin_memory = True, \n",
    "    drop_last = False\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train loop."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-20T20:08:23.607432Z",
     "iopub.status.busy": "2023-03-20T20:08:23.607153Z",
     "iopub.status.idle": "2023-03-20T20:08:23.629454Z",
     "shell.execute_reply": "2023-03-20T20:08:23.628212Z",
     "shell.execute_reply.started": "2023-03-20T20:08:23.607405Z"
    }
   },
   "outputs": [],
   "source": [
    "def train(model, train_loader, test_loader, \n",
    "          epochs=20, lr=0.0001, checkpoint_period=None, weight_decay=1e-4,\n",
    "          warmup_epochs=2, gamma=0.93, verbose=True):\n",
    "    \n",
    "    opt = AdamW(model.parameters(), lr=lr * gamma ** -warmup_epochs, weight_decay=weight_decay)\n",
    "    \n",
    "    model.to(device)\n",
    "    loss_fn = torch.nn.CrossEntropyLoss(label_smoothing=0.01)   \n",
    "    opt.zero_grad() \n",
    "    torch.cuda.empty_cache()\n",
    "    # gc.collect()\n",
    "    scheduler = ChainedScheduler([LinearLR(opt, start_factor=0.02, total_iters=warmup_epochs),\n",
    "                                  ExponentialLR(opt, gamma=gamma)])\n",
    "    if verbose:\n",
    "            print(f'Lr: {scheduler.get_last_lr()[0]:.9f}')\n",
    "    if checkpoint_period is None:\n",
    "        checkpoint_period = len(train_loader)\n",
    "    \n",
    "    max_f1 = 0.\n",
    "    best_epoch = 0\n",
    "    \n",
    "    for epoch in tqdm(range(1, epochs+1, 1)):\n",
    "        # TRAIN\n",
    "        model.train()\n",
    "        loss_avg = 0.\n",
    "        if verbose:\n",
    "            print(f'\\n Epoch={epoch}')\n",
    "        for step, batch in tqdm(enumerate(train_loader), total=len(train_loader), disable = not verbose):\n",
    "            text_input = batch[0].to(device)\n",
    "            image_input = batch[1].to(device)\n",
    "            target = batch[2].to(device)\n",
    "            output = model(text_input, image_input)\n",
    "            loss = loss_fn(output, target)\n",
    "            loss.backward()\n",
    "            opt.step()\n",
    "            opt.zero_grad()\n",
    "            loss_avg += loss.item() / checkpoint_period\n",
    "            if step % checkpoint_period == checkpoint_period - 1:\n",
    "                if verbose:\n",
    "                    print(f'Step={step+1}, Train loss={loss_avg:.6f}')\n",
    "                loss_avg = 0.\n",
    "                model.eval()\n",
    "                grun_truth = []\n",
    "                predicted = []                \n",
    "                with torch.no_grad():\n",
    "                    precision = 0.\n",
    "                    recall = 0.\n",
    "                    total = min(len(test_loader), (checkpoint_period // 2))\n",
    "                    for step, batch in enumerate(test_loader):\n",
    "                        text_input = batch[0].to(device)\n",
    "                        image_input = batch[1].to(device)\n",
    "                        target = batch[2].to(device)\n",
    "                        output = model(text_input, image_input)\n",
    "                        loss = loss_fn(output, target)\n",
    "                        loss_avg += loss.item() / total\n",
    "                        grun_truth.append(target.cpu())\n",
    "                        predicted.append(output.argmax(dim=1).cpu())\n",
    "                        if step >= checkpoint_period // 2 - 1:\n",
    "                            break\n",
    "                weighted_f1 = f1_score(np.concatenate(grun_truth), np.concatenate(predicted), average='weighted')\n",
    "                \n",
    "                if weighted_f1 > max_f1:\n",
    "                    max_f1 = weighted_f1\n",
    "                    best_epoch = epoch\n",
    "                    torch.save(model.state_dict(), os.path.join(WORKDIR, 'checkpoints/best_stack.pt'))\n",
    "\n",
    "                if verbose:\n",
    "                    print(f\"F1={weighted_f1:.5f}\")\n",
    "                    print(f'Eval loss={loss_avg:.5f}\\n')\n",
    "                loss_avg = 0.\n",
    "                model.train()\n",
    "                scheduler.step()\n",
    "                if verbose:\n",
    "                    print(f'Lr: {scheduler.get_last_lr()[0]:.9f}')\n",
    "    return max_f1, best_epoch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Создание модели."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-20T20:08:23.631595Z",
     "iopub.status.busy": "2023-03-20T20:08:23.631219Z",
     "iopub.status.idle": "2023-03-20T20:08:26.627480Z",
     "shell.execute_reply": "2023-03-20T20:08:26.626335Z",
     "shell.execute_reply.started": "2023-03-20T20:08:23.631557Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at cointegrated/rubert-tiny2 were not used when initializing BertModel: ['cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.bias', 'cls.predictions.transform.dense.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "36"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = STACKED_CLF(CFG, len(cls2id), img_emb_mult=0.001).to(device)\n",
    "if CFG.state_dict is not None:\n",
    "    model.load_state_dict(CFG.state_dict)\n",
    "torch.cuda.empty_cache()\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Обучение модели."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-20T20:08:26.629481Z",
     "iopub.status.busy": "2023-03-20T20:08:26.628999Z",
     "iopub.status.idle": "2023-03-20T20:40:48.621750Z",
     "shell.execute_reply": "2023-03-20T20:40:48.618733Z",
     "shell.execute_reply.started": "2023-03-20T20:08:26.629442Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lr: 0.000004625\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b364ae01858f4e13b96e351dd634c43e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Epoch=1\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9c81771bd3c04aa09b62764e6188bb0b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/348 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step=348, Train loss=3.607946\n",
      "F1=0.58541\n",
      "Eval loss=2.91270\n",
      "\n",
      "Lr: 0.000109677\n",
      "\n",
      " Epoch=2\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1ec7dcf803064101b30c7ca99d00ae35",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/348 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step=348, Train loss=0.621298\n",
      "F1=0.89366\n",
      "Eval loss=0.51924\n",
      "\n",
      "Lr: 0.000200000\n",
      "\n",
      " Epoch=3\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bd79d5373cf243db9bd9ef1e1e0ca5ef",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/348 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step=348, Train loss=0.226212\n",
      "F1=0.90193\n",
      "Eval loss=0.48003\n",
      "\n",
      "Lr: 0.000186000\n",
      "\n",
      " Epoch=4\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2dc94429a1914bbe9e5af58a221e75cb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/348 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step=348, Train loss=0.171213\n",
      "F1=0.90349\n",
      "Eval loss=0.47422\n",
      "\n",
      "Lr: 0.000172980\n",
      "\n",
      " Epoch=5\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "724d04f4b71649bfb17394dc5fc5fdca",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/348 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step=348, Train loss=0.154754\n",
      "F1=0.90876\n",
      "Eval loss=0.48116\n",
      "\n",
      "Lr: 0.000160871\n",
      "\n",
      " Epoch=6\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "98f210089f9a4744bf328de116982773",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/348 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step=348, Train loss=0.147399\n",
      "F1=0.91401\n",
      "Eval loss=0.48647\n",
      "\n",
      "Lr: 0.000149610\n",
      "\n",
      " Epoch=7\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0f760ec10e134e8da134029694097352",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/348 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step=348, Train loss=0.143692\n",
      "F1=0.91064\n",
      "Eval loss=0.49526\n",
      "\n",
      "Lr: 0.000139138\n",
      "\n",
      " Epoch=8\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1a49166c208c4463a9e1f5365a4717ff",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/348 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step=348, Train loss=0.141393\n",
      "F1=0.90807\n",
      "Eval loss=0.50745\n",
      "\n",
      "Lr: 0.000129398\n",
      "\n",
      " Epoch=9\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c4cb835ff3044116b84adb086c75baac",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/348 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step=348, Train loss=0.140379\n",
      "F1=0.90852\n",
      "Eval loss=0.50873\n",
      "\n",
      "Lr: 0.000120340\n",
      "\n",
      " Epoch=10\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "16492b81d8bf4d328c8fcd9fd775d922",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/348 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step=348, Train loss=0.138634\n",
      "F1=0.90846\n",
      "Eval loss=0.51588\n",
      "\n",
      "Lr: 0.000111916\n",
      "\n",
      " Epoch=11\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4946746507c847079679d42652d75da5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/348 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step=348, Train loss=0.137302\n",
      "F1=0.90909\n",
      "Eval loss=0.51885\n",
      "\n",
      "Lr: 0.000104082\n",
      "\n",
      " Epoch=12\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2018941fdac1439d949c7512f348c9fc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/348 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_26271/4170444158.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m train(model, train_loader, valid_loader, \n\u001b[0m\u001b[1;32m      2\u001b[0m       warmup_epochs=2, epochs=20, lr=0.0002, gamma=0.93) \n",
      "\u001b[0;32m/tmp/ipykernel_26271/70887553.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(model, train_loader, test_loader, epochs, lr, checkpoint_period, weight_decay, warmup_epochs, gamma, verbose)\u001b[0m\n\u001b[1;32m     32\u001b[0m             \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext_input\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimage_input\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m             \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 34\u001b[0;31m             \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     35\u001b[0m             \u001b[0mopt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m             \u001b[0mopt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/lib/python3.9/site-packages/torch/_tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    486\u001b[0m                 \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    487\u001b[0m             )\n\u001b[0;32m--> 488\u001b[0;31m         torch.autograd.backward(\n\u001b[0m\u001b[1;32m    489\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    490\u001b[0m         )\n",
      "\u001b[0;32m~/anaconda/lib/python3.9/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    195\u001b[0m     \u001b[0;31m# some Python versions print out the first line of a multi-line function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    196\u001b[0m     \u001b[0;31m# calls in the traceback and some print out the last line\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 197\u001b[0;31m     Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n\u001b[0m\u001b[1;32m    198\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    199\u001b[0m         allow_unreachable=True, accumulate_grad=True)  # Calls into the C++ engine to run the backward pass\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "train(model, train_loader, valid_loader, \n",
    "      warmup_epochs=2, epochs=3, lr=0.00025, gamma=0.93) \n",
    "train(model, train_loader, valid_loader, \n",
    "      warmup_epochs=2, epochs=20, lr=0.0002, gamma=0.93) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SUBMIT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Загружаем лучший чекпоинт модели."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-20T20:41:50.312185Z",
     "iopub.status.busy": "2023-03-20T20:41:50.311783Z",
     "iopub.status.idle": "2023-03-20T20:41:50.459882Z",
     "shell.execute_reply": "2023-03-20T20:41:50.458792Z",
     "shell.execute_reply.started": "2023-03-20T20:41:50.312147Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.load_state_dict(torch.load(os.path.join(WORKDIR, 'checkpoints/best_stack.pt')))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Функция для проверки и генерации ответов (на всякий случай, проверяем, что метрики соответствуют ожидаемым метрикам лучшего чекпоинта)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-20T20:58:56.292520Z",
     "iopub.status.busy": "2023-03-20T20:58:56.291767Z",
     "iopub.status.idle": "2023-03-20T20:58:56.305604Z",
     "shell.execute_reply": "2023-03-20T20:58:56.302846Z",
     "shell.execute_reply.started": "2023-03-20T20:58:56.292482Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_predictions_eval(model, test_loader) -> np.array:\n",
    "    model.eval()\n",
    "    total = len(test_loader)\n",
    "    predicted = []\n",
    "    grun_truth = []\n",
    "    for step, batch in tqdm(enumerate(test_loader), total=total):\n",
    "        with torch.no_grad():\n",
    "            text_input = batch[0].to(device)\n",
    "            image_input = batch[1].to(device)\n",
    "            target = batch[2].to(device)\n",
    "            output = model(text_input, image_input)\n",
    "            predicted.append(output.argmax(dim=1).cpu())\n",
    "            grun_truth.append(target.cpu())\n",
    "    weighted_f1 = f1_score(np.concatenate(grun_truth), np.concatenate(predicted), average='weighted')\n",
    "    print(f\"F1={weighted_f1:.5f}\")\n",
    "    return np.concatenate(predicted)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Делаем проверки:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-20T20:55:50.334651Z",
     "iopub.status.busy": "2023-03-20T20:55:50.333742Z",
     "iopub.status.idle": "2023-03-20T20:57:08.031828Z",
     "shell.execute_reply": "2023-03-20T20:57:08.030547Z",
     "shell.execute_reply.started": "2023-03-20T20:55:50.334598Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0026be3db1be452fb389e2d84b77024d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/178 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7fbf133a5ee0>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ubuntu/anaconda/lib/python3.9/site-packages/torch/utils/data/dataloader.py\", line 1466, in __del__\n",
      "    self._shutdown_workers()\n",
      "  File \"/home/ubuntu/anaconda/lib/python3.9/site-packages/torch/utils/data/dataloader.py\", line 1449, in _shutdown_workers\n",
      "    if w.is_alive():\n",
      "  File \"/home/ubuntu/anaconda/lib/python3.9/multiprocessing/process.py\", line 160, in is_alive\n",
      "    assert self._parent_pid == os.getpid(), 'can only test a child process'Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7fbf133a5ee0>\n",
      "\n",
      "Exception ignored in: AssertionErrorTraceback (most recent call last):\n",
      "<function _MultiProcessingDataLoaderIter.__del__ at 0x7fbf133a5ee0>\n",
      "  File \"/home/ubuntu/anaconda/lib/python3.9/site-packages/torch/utils/data/dataloader.py\", line 1466, in __del__\n",
      "    self._shutdown_workers()\n",
      "  File \"/home/ubuntu/anaconda/lib/python3.9/site-packages/torch/utils/data/dataloader.py\", line 1449, in _shutdown_workers\n",
      "    if w.is_alive():\n",
      "  File \"/home/ubuntu/anaconda/lib/python3.9/multiprocessing/process.py\", line 160, in is_alive\n",
      "    assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
      "AssertionError: can only test a child process: Traceback (most recent call last):\n",
      "Exception ignored in:   File \"/home/ubuntu/anaconda/lib/python3.9/site-packages/torch/utils/data/dataloader.py\", line 1466, in __del__\n",
      "can only test a child process<function _MultiProcessingDataLoaderIter.__del__ at 0x7fbf133a5ee0>    \n",
      "\n",
      "\n",
      "self._shutdown_workers()Traceback (most recent call last):\n",
      "  File \"/home/ubuntu/anaconda/lib/python3.9/site-packages/torch/utils/data/dataloader.py\", line 1466, in __del__\n",
      "\n",
      "Exception ignored in:   File \"/home/ubuntu/anaconda/lib/python3.9/site-packages/torch/utils/data/dataloader.py\", line 1449, in _shutdown_workers\n",
      "<function _MultiProcessingDataLoaderIter.__del__ at 0x7fbf133a5ee0>    if w.is_alive():\n",
      "  File \"/home/ubuntu/anaconda/lib/python3.9/multiprocessing/process.py\", line 160, in is_alive\n",
      "    assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
      "    \n",
      "self._shutdown_workers()Traceback (most recent call last):\n",
      "AssertionError  File \"/home/ubuntu/anaconda/lib/python3.9/site-packages/torch/utils/data/dataloader.py\", line 1466, in __del__\n",
      "    : Exception ignored in: Exception ignored in: \n",
      "  File \"/home/ubuntu/anaconda/lib/python3.9/site-packages/torch/utils/data/dataloader.py\", line 1449, in _shutdown_workers\n",
      "<function _MultiProcessingDataLoaderIter.__del__ at 0x7fbf133a5ee0>can only test a child process<function _MultiProcessingDataLoaderIter.__del__ at 0x7fbf133a5ee0>self._shutdown_workers()\n",
      "\n",
      "\n",
      "    Traceback (most recent call last):\n",
      "  File \"/home/ubuntu/anaconda/lib/python3.9/site-packages/torch/utils/data/dataloader.py\", line 1466, in __del__\n",
      "    \n",
      "self._shutdown_workers()\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ubuntu/anaconda/lib/python3.9/site-packages/torch/utils/data/dataloader.py\", line 1449, in _shutdown_workers\n",
      "    if w.is_alive():if w.is_alive():  File \"/home/ubuntu/anaconda/lib/python3.9/site-packages/torch/utils/data/dataloader.py\", line 1466, in __del__\n",
      "    self._shutdown_workers()\n",
      "  File \"/home/ubuntu/anaconda/lib/python3.9/site-packages/torch/utils/data/dataloader.py\", line 1449, in _shutdown_workers\n",
      "    \n",
      "\n",
      "  File \"/home/ubuntu/anaconda/lib/python3.9/site-packages/torch/utils/data/dataloader.py\", line 1449, in _shutdown_workers\n",
      "if w.is_alive():\n",
      "  File \"/home/ubuntu/anaconda/lib/python3.9/multiprocessing/process.py\", line 160, in is_alive\n",
      "  File \"/home/ubuntu/anaconda/lib/python3.9/multiprocessing/process.py\", line 160, in is_alive\n",
      "        Exception ignored in: if w.is_alive():      File \"/home/ubuntu/anaconda/lib/python3.9/multiprocessing/process.py\", line 160, in is_alive\n",
      "\n",
      "assert self._parent_pid == os.getpid(), 'can only test a child process'  File \"/home/ubuntu/anaconda/lib/python3.9/multiprocessing/process.py\", line 160, in is_alive\n",
      "\n",
      "    assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
      "AssertionError: assert self._parent_pid == os.getpid(), 'can only test a child process'AssertionError<function _MultiProcessingDataLoaderIter.__del__ at 0x7fbf133a5ee0>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ubuntu/anaconda/lib/python3.9/site-packages/torch/utils/data/dataloader.py\", line 1466, in __del__\n",
      "        : can only test a child processself._shutdown_workers()assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
      "can only test a child process  File \"/home/ubuntu/anaconda/lib/python3.9/site-packages/torch/utils/data/dataloader.py\", line 1449, in _shutdown_workers\n",
      "    \n",
      "\n",
      "\n",
      "\n",
      "if w.is_alive():AssertionErrorAssertionError: : can only test a child process\n",
      "can only test a child process\n",
      "  File \"/home/ubuntu/anaconda/lib/python3.9/multiprocessing/process.py\", line 160, in is_alive\n",
      "\n",
      "    assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
      "AssertionError: can only test a child process\n"
     ]
    }
   ],
   "source": [
    "predictions = get_predictions_eval(model, full_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.img_emb_mult=0.001\n",
    "_ = get_predictions_eval(model, valid_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Генерируем предсказания для тестовой выборки:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-20T20:58:58.777974Z",
     "iopub.status.busy": "2023-03-20T20:58:58.777036Z",
     "iopub.status.idle": "2023-03-20T20:59:12.996320Z",
     "shell.execute_reply": "2023-03-20T20:59:12.995027Z",
     "shell.execute_reply.started": "2023-03-20T20:58:58.777915Z"
    }
   },
   "outputs": [],
   "source": [
    "predictions_test = get_predictions_eval(model, test_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Смотрим, что получилось:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-20T20:57:48.324279Z",
     "iopub.status.busy": "2023-03-20T20:57:48.323580Z",
     "iopub.status.idle": "2023-03-20T20:57:48.375436Z",
     "shell.execute_reply": "2023-03-20T20:57:48.374485Z",
     "shell.execute_reply.started": "2023-03-20T20:57:48.324236Z"
    }
   },
   "outputs": [],
   "source": [
    "data_full['predictions'] = [cls2id[x] for x in predictions]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-20T20:58:37.419147Z",
     "iopub.status.busy": "2023-03-20T20:58:37.418426Z",
     "iopub.status.idle": "2023-03-20T20:58:37.442175Z",
     "shell.execute_reply": "2023-03-20T20:58:37.441006Z",
     "shell.execute_reply.started": "2023-03-20T20:58:37.419107Z"
    }
   },
   "outputs": [],
   "source": [
    "data_full[data_full.category_id == data_full.predictions]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-20T20:58:37.517795Z",
     "iopub.status.busy": "2023-03-20T20:58:37.517462Z",
     "iopub.status.idle": "2023-03-20T20:58:37.535310Z",
     "shell.execute_reply": "2023-03-20T20:58:37.534390Z",
     "shell.execute_reply.started": "2023-03-20T20:58:37.517766Z"
    }
   },
   "outputs": [],
   "source": [
    "data_full[data_full.category_id != data_full.predictions]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Смотрим, что получили на тестовой выборке (проверяем адекватность предикта глазами):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-20T20:59:28.524913Z",
     "iopub.status.busy": "2023-03-20T20:59:28.523974Z",
     "iopub.status.idle": "2023-03-20T20:59:28.541073Z",
     "shell.execute_reply": "2023-03-20T20:59:28.539772Z",
     "shell.execute_reply.started": "2023-03-20T20:59:28.524869Z"
    }
   },
   "outputs": [],
   "source": [
    "data_test['predicted_category_id'] = [cls2id[x] for x in predictions_test]\n",
    "data_test['predicted_category'] = [id2category[cls2id[x]] for x in predictions_test]\n",
    "data_test.to_csv('result_watch.csv') \n",
    "data_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Готовим данные для сохранения в соответствии с требованиями задания:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_test.drop(columns=['Document', 'predicted_category'], inplace=True)\n",
    "data_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-20T20:59:53.470907Z",
     "iopub.status.busy": "2023-03-20T20:59:53.470485Z",
     "iopub.status.idle": "2023-03-20T20:59:53.831288Z",
     "shell.execute_reply": "2023-03-20T20:59:53.830114Z",
     "shell.execute_reply.started": "2023-03-20T20:59:53.470872Z"
    }
   },
   "outputs": [],
   "source": [
    "data_test.to_parquet('result.parquet')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Проверим, как таблица сохранилась:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.read_parquet('result.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
